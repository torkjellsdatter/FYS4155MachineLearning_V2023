{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0c8729",
   "metadata": {},
   "source": [
    "WEEKLY EXERCISE 3 (WEEK 37) \n",
    "BRAGE BREVIG\n",
    "\n",
    "Exercise 1a)\n",
    "\n",
    "Under the assumption that we may describe our data under a contiunous function $\\mathbf{y} = f(\\mathbf{x}) + \\epsilon, \\space \\epsilon \\space \\sim \\space  N\\left(0,\\sigma^2\\right)$ such that \n",
    "$$\n",
    "y_i = X_{i,*}\\boldsymbol{\\beta} + \\epsilon_i\n",
    "$$\n",
    "\n",
    "the expectation value of a data point $y_i$ may be given by\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\left[y_i\\right] = \\mathbb{E}\\left[X_{i,*}\\boldsymbol{\\beta} + \\epsilon_i\\right] = \\mathbb{E}\\left[X_{i,*}\\boldsymbol{\\beta}\\right] +\\mathbb{E}\\left[\\epsilon\\right] = X_{i,*}\\beta_i\n",
    "$$\n",
    "\n",
    "as the noise term is normally distributed around 0 and the expected value of the parameterization of the data is centered around the parameters $\\beta_i$.\n",
    "\n",
    "Exercise 1b)\n",
    "\n",
    "The variance of the data points $\\text{Var}(y_i)$ is by definition given by\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\left[y_{i}^{2}\\right] - \\left(\\mathbb{E}\\left[y_i\\right]\\right)^2 = \\mathbb{E}\\left(X_{i,*}\\boldsymbol{\\beta} + \\epsilon\\right)^2 - \\left(X_{i,*}\\boldsymbol{\\beta}\\right)^2\n",
    "$$\n",
    "\n",
    "Leading to \n",
    "\n",
    "$$\n",
    "\\text{Var}(y_i) = \\mathbb{E}\\left[\\left(X_{i,*}\\boldsymbol{\\beta}\\right)^2\\right] + 2\\mathbb{E}\\left[\\epsilon\\right]X_{i,*}\\boldsymbol{\\beta} + \\mathbb{E}\\left[\\epsilon^2\\right] - \\left(X_{i,*}\\boldsymbol{\\beta}\\right)^2 = \\mathbb{E}\\left[\\epsilon^2\\right] = \\sigma^2\n",
    "$$\n",
    "\n",
    "Exercise 1c)\n",
    "\n",
    "Under OLS we obtain the optimal parameterization of the model by $\\boldsymbol{\\beta} = \\left(\\mathbf{X}^T\\mathbf{X}\\right)^{-1}\\mathbf{X}^T \\mathbf{y}$. The feature matrix contains fixed values, and so the expectation value $\\mathbb{E}\\left[\\boldsymbol{\\beta}\\right]$ is conditional in $\\mathbf{y}$ only, such that\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\left[\\boldsymbol{\\beta}\\right] = \\left(\\mathbf{X}^T\\mathbf{X}\\right)^{-1}\\mathbf{X}^T\\mathbb{E}\\left[\\mathbf{y}\\right] = \\left(\\mathbf{X}^T\\mathbf{X}\\right)^{-1}\\mathbf{X}^T\\mathbb{E}\\left[\\mathbf{X}\\boldsymbol{\\beta}\\right] = \\left(\\mathbf{X}^T\\mathbf{X}\\right)^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} = \\mathbf{I}\\boldsymbol{\\beta} = \\boldsymbol{\\beta}\n",
    "$$\n",
    "\n",
    "here employing the result from the subtask above. \n",
    "\n",
    "Exercise 1d) \n",
    "Now, for the variance of the regressor coefficients $\\text{Var}(\\boldsymbol{\\beta})$ we see that under the definition of variance\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\boldsymbol{\\beta}) = \\mathbb{E}\\left[\\boldsymbol{\\beta}^2\\right] - \\mathbb{E}\\left[\\boldsymbol{\\beta}\\right]^2 = \\mathbb{E}\\left[\\left(\\left(\\mathbf{X}^T\\mathbf{X}\\right)^{-1}\\mathbf{X}^T\\mathbf{y}\\right)^2\\right] - \\boldsymbol{\\beta}^2 = \\mathbb{E}\\left[\\left(\\left(\\mathbf{X}^T\\mathbf{X}\\right)^{-1}\\mathbf{X}^T\\left(\\mathbf{X}\\boldsymbol{\\beta} + \\epsilon \\right)\\right)^2\\right] - \\boldsymbol{\\beta}^2 = \\mathbb{E}[\\boldsymbol{\\beta}^2] + \\mathbb{E}\\left[\\left(\\left(\\mathbf{X}^T\\mathbf{X}\\right)^{-1}\\mathbf{X}^T \\epsilon\\right)^2\\right] - \\boldsymbol{\\beta}^2\n",
    "\\$$\n",
    "\n",
    "which, using the results for the expectation value of the regressor coefficient and the fact that $\\mathbb{E}\\left[\\epsilon\\right] = 0$ and $\\mathbb{E}\\left[\\epsilon^2\\right] = \\sigma^2$, leads us to\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\beta) = \\sigma^2\\left(\\mathbf{X}^T\\mathbf{X}\\right)^{-1}\n",
    "$$\n",
    "\n",
    "Exercise 2a)\n",
    "\n",
    "From the result above it is easy to infer that the expectation value of the regressor coefficients under Ridge Regression are given by\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\left[\\boldsymbol{\\beta}^{Ridge}\\right] = \\mathbb{E}\\left[\\left(\\mathbf{X}^T\\mathbf{X} + \\lambda \\mathbf{I}\\right)^{-1}\\mathbf{X}^T\\mathbf{y}\\right] = \\left(\\mathbf{X}^T\\mathbf{X} + \\lambda \\mathbf{I}\\right)^{-1}\\mathbf{X}^T\\mathbb{E}\\left[\\mathbf{y}\\right] = \\left(\\mathbf{X}^T\\mathbf{X} + \\lambda \\mathbf{I}\\right)^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebd781f",
   "metadata": {},
   "source": [
    "Exercise 2b)\n",
    "\n",
    "I will add to this exercise two photos of handwritten notes for the problem. I tried to go about the problem as I did in Exercise 1d) with no luck. Photos will be uploaded alongside this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df1a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
